{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac25240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEQ_LEN       = 50\n",
    "SPLIT         = 0.8\n",
    "LOSS_W_CONT   = 0.5\n",
    "TEMP          = 1.0\n",
    "NOISE_STD     = 0.05\n",
    "CAP_STEP      = 2.0\n",
    "CAP_DURATION  = 2.0\n",
    "SHOW_PPL      = True\n",
    "USE_SCHEDULER = True\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pretty_midi\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def extract_features(midi_file):\n",
    "    pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "    inst = pm.instruments[0]\n",
    "    notes = inst.notes\n",
    "\n",
    "    pitches, steps, durations, velocities = [], [], [], []\n",
    "    prev_time = 0.0\n",
    "\n",
    "    for i, note in enumerate(notes):\n",
    "        pitches.append(note.pitch)\n",
    "        start = note.start\n",
    "        dur = note.end - start\n",
    "        vel = note.velocity\n",
    "        step = start - prev_time if i > 0 else 0.0\n",
    "        steps.append(step); durations.append(dur); velocities.append(vel)\n",
    "        prev_time = start\n",
    "\n",
    "    steps = torch.tensor(steps, dtype=torch.float32)\n",
    "    durations = torch.tensor(durations, dtype=torch.float32)\n",
    "    velocities = torch.tensor(velocities, dtype=torch.float32)\n",
    "    pitches = torch.tensor(pitches, dtype=torch.long)\n",
    "\n",
    "    step_max = steps.max().item() + 0.00001\n",
    "    duration_max = durations.max().item() + 0.00001\n",
    "\n",
    "    steps = steps / step_max\n",
    "    durations = durations / duration_max\n",
    "    velocities = velocities / 127.0\n",
    "\n",
    "\n",
    "    cont_features = torch.stack([steps, durations, velocities], dim=1)\n",
    "    return pitches, cont_features, step_max, duration_max\n",
    "\n",
    "\n",
    "def load_all_data(dataset_dir):\n",
    "    pitches_all, cont_all = [], []\n",
    "    step_max_global, duration_max_global = 0.0, 0.0\n",
    "\n",
    "    for filename in sorted(os.listdir(dataset_dir)):\n",
    "        if filename.lower().endswith(('.mid', '.midi')):\n",
    "            p, c, step_max, duration_max = extract_features(os.path.join(dataset_dir, filename))\n",
    "            pitches_all.append(p); cont_all.append(c)\n",
    "            step_max_global = max(step_max_global, step_max)\n",
    "            duration_max_global = max(duration_max_global, duration_max)\n",
    "\n",
    "    pitches_all = torch.cat(pitches_all)\n",
    "    cont_all = torch.cat(cont_all)\n",
    "    return pitches_all, cont_all, step_max_global, duration_max_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83246db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(pitches, cont_features, seq_length):\n",
    "    pitch_seqs, cont_seqs, pitch_targets, cont_targets = [], [], [], []\n",
    "    for i in range(len(pitches) - seq_length):\n",
    "        pitch_seqs.append(pitches[i:i + seq_length])\n",
    "        cont_seqs.append(cont_features[i:i + seq_length])\n",
    "        pitch_targets.append(pitches[i + seq_length])\n",
    "        cont_targets.append(cont_features[i + seq_length])\n",
    "\n",
    "    return (torch.stack(pitch_seqs),\n",
    "            torch.stack(cont_seqs),\n",
    "            torch.tensor(pitch_targets),\n",
    "            torch.stack(cont_targets))\n",
    "\n",
    "\n",
    "def temporal_split_before_window(pitches, cont, split_ratio=0.8):\n",
    "    n_total = len(pitches)\n",
    "    cut = int(n_total * split_ratio)\n",
    "    return (pitches[:cut], cont[:cut]), (pitches[cut:], cont[cut:])\n",
    "\n",
    "\n",
    "class MusicLSTMMultiOutput(nn.Module):\n",
    "    def __init__(self, n_pitches=128, embed_size=32, hidden_size=128, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(n_pitches, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size + 3, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.hidden_fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.pitch_fc = nn.Linear(hidden_size, n_pitches)\n",
    "        self.cont_fc = nn.Linear(hidden_size, 3)\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "        pitch_emb = self.embed(pitch_seq)\n",
    "        x = torch.cat([pitch_emb, cont_seq], dim=2)\n",
    "        out, _ = self.lstm(x)\n",
    "        h = F.relu(self.hidden_fc(out[:, -1, :]))\n",
    "        return self.pitch_fc(h), self.cont_fc(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb2eed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, epochs=20, batch_size=64, lr=0.001, device='cpu'):\n",
    "    model.to(device)\n",
    "    opt   = optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3, verbose=True) if USE_SCHEDULER else None\n",
    "\n",
    "    ce_loss  = nn.CrossEntropyLoss()\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    tr_seq_p, tr_seq_c, tr_tgt_p, tr_tgt_c = train_data\n",
    "    va_seq_p, va_seq_c, va_tgt_p, va_tgt_c = val_data\n",
    "\n",
    "    va_seq_p = va_seq_p.to(device); va_seq_c = va_seq_c.to(device)\n",
    "    va_tgt_p = va_tgt_p.to(device); va_tgt_c = va_tgt_c.to(device)\n",
    "\n",
    "    n_train = len(tr_seq_p)\n",
    "    n_steps = max(1, (n_train + batch_size - 1) // batch_size)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        order = torch.randperm(n_train)\n",
    "        loss_sum = 0.0\n",
    "        ce_sum   = 0.0\n",
    "        acc_sum  = 0.0\n",
    "\n",
    "        for i in range(0, n_train, batch_size):\n",
    "            idx  = order[i:i+batch_size]\n",
    "            pseq = tr_seq_p[idx].to(device)\n",
    "            cseq = tr_seq_c[idx].to(device)\n",
    "            ptgt = tr_tgt_p[idx].to(device)\n",
    "            ctgt = tr_tgt_c[idx].to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits, cout = model(pseq, cseq)\n",
    "            lp = ce_loss(logits, ptgt)\n",
    "            lc = mse_loss(cout, ctgt)\n",
    "            loss = lp + LOSS_W_CONT * lc\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            ce_sum   += lp.item()\n",
    "            acc_sum  += (logits.argmax(dim=1) == ptgt).float().mean().item()\n",
    "\n",
    "        tr_loss = loss_sum / n_steps\n",
    "        tr_acc  = acc_sum  / n_steps\n",
    "        tr_ppl  = math.exp(ce_sum / n_steps)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            v_logits, v_cont = model(va_seq_p, va_seq_c)\n",
    "            v_ce   = ce_loss(v_logits, va_tgt_p).item()\n",
    "            v_mse  = mse_loss(v_cont,  va_tgt_c).item()\n",
    "            v_loss = v_ce + LOSS_W_CONT * v_mse\n",
    "            v_acc  = (v_logits.argmax(dim=1) == va_tgt_p).float().mean().item()\n",
    "            v_ppl  = math.exp(v_ce)\n",
    "\n",
    "        msg = f\"Ep {ep+1}/{epochs} | loss {tr_loss:.4f} | acc {tr_acc:.3f} | vloss {v_loss:.4f} | vacc {v_acc:.3f}\"\n",
    "        if SHOW_PPL:\n",
    "            msg += f\" | ppl {tr_ppl:.2f} | vppl {v_ppl:.2f}\"\n",
    "        print(msg)\n",
    "\n",
    "        if sched is not None:\n",
    "            sched.step(v_loss)\n",
    "\n",
    "def sample_pitch(logits, temperature=1.0):\n",
    "    logits = logits / max(temperature, 1e-8)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    return int(torch.multinomial(probs, 1).item())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence_multi(model, seed_pitch, seed_cont, length=200, temperature=TEMP,\n",
    "                            noise_std=NOISE_STD, step_max=1.0, duration_max=1.0, device='cpu'):\n",
    "    model.eval()\n",
    "    out_p = []\n",
    "    out_c = []\n",
    "    pitch_seq = seed_pitch.clone().to(device)\n",
    "    cont_seq = seed_cont.clone().to(device)\n",
    "\n",
    "    for _ in range(length):\n",
    "        with torch.no_grad():\n",
    "            plogits, cout = model(pitch_seq.unsqueeze(0), cont_seq.unsqueeze(0))\n",
    "\n",
    "        pidx = sample_pitch(plogits.squeeze(0).cpu(), temperature)\n",
    "\n",
    "        cvals = cout.squeeze(0).cpu()\n",
    "        if noise_std > 0:\n",
    "            cvals = cvals + torch.randn(3) * noise_std\n",
    "        cvals = cvals.clamp(min=0.0)\n",
    "        cvals[0] = cvals[0] * step_max\n",
    "        cvals[1] = cvals[1] * duration_max\n",
    "        cvals[2] = cvals[2].clamp(max=1.0)\n",
    "\n",
    "        out_p.append(pidx)\n",
    "        out_c.append(cvals)\n",
    "\n",
    "        pitch_seq = torch.cat([pitch_seq[1:], torch.tensor([pidx], device=device)])\n",
    "        cont_seq = torch.cat([\n",
    "            cont_seq[1:],\n",
    "            (cvals / torch.tensor([step_max, duration_max, 1.0])).unsqueeze(0).to(device)\n",
    "        ])\n",
    "\n",
    "    return torch.tensor(out_p), torch.stack(out_c)\n",
    "\n",
    "def save_midi(pitches, cont_features, output_file):\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    inst = pretty_midi.Instrument(program=0)\n",
    "    t = 0.0\n",
    "\n",
    "    for i in range(len(pitches)):\n",
    "        pitch = int(pitches[i].item())\n",
    "        step = float(cont_features[i][0].item())\n",
    "        duration = float(cont_features[i][1].item())\n",
    "        velocity = int(cont_features[i][2].item() * 127)\n",
    "\n",
    "        if step > CAP_STEP:\n",
    "            step = CAP_STEP\n",
    "        if duration > CAP_DURATION:\n",
    "            duration = CAP_DURATION\n",
    "\n",
    "        t = t + step\n",
    "        start_time = t\n",
    "        end_time = start_time + max(duration, 0.05)\n",
    "        inst.notes.append(pretty_midi.Note(velocity=velocity, pitch=pitch, start=start_time, end=end_time))\n",
    "\n",
    "    pm.instruments.append(inst)\n",
    "    pm.write(output_file)\n",
    "    print(\"Archivo MIDI guardado en:\", output_file)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_all(model, pitch_seqs, cont_seqs, pitch_tg, cont_tg,\n",
    "                 step_max, duration_max, device='cpu', batch_size=1024):\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "    ce_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    pitch_seqs = pitch_seqs.to(device)\n",
    "    cont_seqs  = cont_seqs.to(device)\n",
    "    pitch_tg   = pitch_tg.to(device)\n",
    "    cont_tg    = cont_tg.to(device)\n",
    "\n",
    "    n = pitch_tg.size(0)\n",
    "    ce_sum = 0.0\n",
    "    acc_sum = 0.0\n",
    "    acc5_sum = 0.0\n",
    "    mse_n = torch.zeros(3)\n",
    "    mae_n = torch.zeros(3)\n",
    "    mse_r = torch.zeros(3)\n",
    "    mae_r = torch.zeros(3)\n",
    "\n",
    "    for i in range(0, n, batch_size):\n",
    "        pseq = pitch_seqs[i:i+batch_size]\n",
    "        cseq = cont_seqs[i:i+batch_size]\n",
    "        ptgt = pitch_tg[i:i+batch_size]\n",
    "        ctgt = cont_tg[i:i+batch_size]\n",
    "\n",
    "        logits, cpred = model(pseq, cseq)\n",
    "        ce_sum += ce_fn(logits, ptgt).item()\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        acc_sum += (pred == ptgt).float().sum().item()\n",
    "\n",
    "        top5 = logits.topk(5, dim=1).indices\n",
    "        acc5_sum += (top5 == ptgt.unsqueeze(1)).any(dim=1).float().sum().item()\n",
    "\n",
    "        diff_n = cpred - ctgt\n",
    "        mse_n += (diff_n ** 2).sum(dim=0).detach().cpu()\n",
    "        mae_n += diff_n.abs().sum(dim=0).detach().cpu()\n",
    "\n",
    "        den = torch.stack([\n",
    "            cpred[:, 0] * step_max,\n",
    "            cpred[:, 1] * duration_max,\n",
    "            cpred[:, 2].clamp(0, 1) * 127.0\n",
    "        ], dim=1)\n",
    "        den_t = torch.stack([\n",
    "            ctgt[:, 0] * step_max,\n",
    "            ctgt[:, 1] * duration_max,\n",
    "            ctgt[:, 2].clamp(0, 1) * 127.0\n",
    "        ], dim=1)\n",
    "\n",
    "        diff_r = den - den_t\n",
    "        mse_r += (diff_r ** 2).sum(dim=0).detach().cpu()\n",
    "        mae_r += diff_r.abs().sum(dim=0).detach().cpu()\n",
    "\n",
    "    ce = ce_sum / n\n",
    "    ppl = math.exp(ce)\n",
    "    acc = acc_sum / n\n",
    "    acc5 = acc5_sum / n\n",
    "\n",
    "    rmse_norm = (mse_n / n).sqrt().tolist()\n",
    "    mae_norm = (mae_n / n).tolist()\n",
    "    rmse_real = (mse_r / n).sqrt().tolist()\n",
    "    mae_real = (mae_r / n).tolist()\n",
    "\n",
    "    return {\n",
    "        \"pitch\": {\"CE\": ce, \"PPL\": ppl, \"acc\": acc, \"top5\": acc5},\n",
    "        \"cont_norm\": {\"RMSE\": rmse_norm, \"MAE\": mae_norm},\n",
    "        \"cont_real\": {\"RMSE_sec_vel\": rmse_real, \"MAE_sec_vel\": mae_real}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab61d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Entrenando modelo...\n",
      "Ep 1/30 | loss 2.8635 | acc 0.135 | vloss 2.5152 | vacc 0.197 | ppl 17.36 | vppl 12.20\n",
      "Ep 2/30 | loss 2.3984 | acc 0.236 | vloss 2.3837 | vacc 0.260 | ppl 10.93 | vppl 10.70\n",
      "Ep 3/30 | loss 2.2085 | acc 0.301 | vloss 2.2837 | vacc 0.314 | ppl 9.04 | vppl 9.70\n",
      "Ep 4/30 | loss 2.0448 | acc 0.354 | vloss 2.2751 | vacc 0.324 | ppl 7.68 | vppl 9.60\n",
      "Ep 5/30 | loss 1.8985 | acc 0.402 | vloss 2.2807 | vacc 0.326 | ppl 6.63 | vppl 9.66\n",
      "Ep 6/30 | loss 1.7663 | acc 0.445 | vloss 2.3351 | vacc 0.336 | ppl 5.81 | vppl 10.20\n",
      "Ep 7/30 | loss 1.6376 | acc 0.488 | vloss 2.3761 | vacc 0.334 | ppl 5.11 | vppl 10.64\n",
      "Ep 8/30 | loss 1.5066 | acc 0.526 | vloss 2.4558 | vacc 0.328 | ppl 4.49 | vppl 11.52\n",
      "Ep 9/30 | loss 1.3430 | acc 0.584 | vloss 2.5318 | vacc 0.327 | ppl 3.81 | vppl 12.43\n",
      "Ep 10/30 | loss 1.2622 | acc 0.609 | vloss 2.5971 | vacc 0.324 | ppl 3.51 | vppl 13.28\n",
      "Ep 11/30 | loss 1.1845 | acc 0.630 | vloss 2.7105 | vacc 0.321 | ppl 3.25 | vppl 14.86\n",
      "Ep 12/30 | loss 1.1343 | acc 0.644 | vloss 2.7660 | vacc 0.314 | ppl 3.09 | vppl 15.71\n",
      "Ep 13/30 | loss 1.0401 | acc 0.678 | vloss 2.8286 | vacc 0.316 | ppl 2.81 | vppl 16.73\n",
      "Ep 14/30 | loss 1.0075 | acc 0.685 | vloss 2.8826 | vacc 0.309 | ppl 2.72 | vppl 17.65\n",
      "Ep 15/30 | loss 0.9762 | acc 0.695 | vloss 2.9396 | vacc 0.318 | ppl 2.64 | vppl 18.68\n",
      "Ep 16/30 | loss 0.9401 | acc 0.709 | vloss 2.9976 | vacc 0.305 | ppl 2.55 | vppl 19.81\n",
      "Ep 17/30 | loss 0.9043 | acc 0.717 | vloss 3.0486 | vacc 0.310 | ppl 2.46 | vppl 20.84\n",
      "Ep 18/30 | loss 0.8828 | acc 0.726 | vloss 3.0679 | vacc 0.303 | ppl 2.40 | vppl 21.25\n",
      "Ep 19/30 | loss 0.8759 | acc 0.729 | vloss 3.0948 | vacc 0.307 | ppl 2.39 | vppl 21.84\n",
      "Ep 20/30 | loss 0.8619 | acc 0.732 | vloss 3.1417 | vacc 0.299 | ppl 2.36 | vppl 22.87\n",
      "Ep 21/30 | loss 0.8328 | acc 0.746 | vloss 3.1511 | vacc 0.307 | ppl 2.29 | vppl 23.09\n",
      "Ep 22/30 | loss 0.8222 | acc 0.745 | vloss 3.1723 | vacc 0.306 | ppl 2.26 | vppl 23.59\n",
      "Ep 23/30 | loss 0.8154 | acc 0.748 | vloss 3.1949 | vacc 0.303 | ppl 2.25 | vppl 24.13\n",
      "Ep 24/30 | loss 0.8087 | acc 0.748 | vloss 3.1984 | vacc 0.303 | ppl 2.23 | vppl 24.21\n",
      "Ep 25/30 | loss 0.8018 | acc 0.752 | vloss 3.2079 | vacc 0.301 | ppl 2.22 | vppl 24.44\n",
      "Ep 26/30 | loss 0.7979 | acc 0.753 | vloss 3.2175 | vacc 0.303 | ppl 2.21 | vppl 24.68\n",
      "Ep 27/30 | loss 0.7961 | acc 0.754 | vloss 3.2246 | vacc 0.302 | ppl 2.21 | vppl 24.86\n",
      "Ep 28/30 | loss 0.7855 | acc 0.757 | vloss 3.2371 | vacc 0.299 | ppl 2.18 | vppl 25.16\n",
      "Ep 29/30 | loss 0.7786 | acc 0.760 | vloss 3.2474 | vacc 0.301 | ppl 2.17 | vppl 25.43\n",
      "Ep 30/30 | loss 0.7808 | acc 0.759 | vloss 3.2477 | vacc 0.301 | ppl 2.17 | vppl 25.43\n",
      "Evaluando validación (todas las cabezas)...\n",
      "{'pitch': {'CE': 3.236117932640521, 'PPL': 25.4347902731586, 'acc': 0.30095312704008353, 'top5': 0.6742394568481525}, 'cont_norm': {'RMSE': [0.14126339554786682, 0.20354574918746948, 0.09130218625068665], 'MAE': [0.08075857162475586, 0.12087191641330719, 0.07427585124969482]}, 'cont_real': {'RMSE_sec_vel': [0.938386082649231, 1.3521161079406738, 11.595378875732422], 'MAE_sec_vel': [0.5364639163017273, 0.8029294013977051, 9.433032035827637]}}\n",
      "Generando secuencia...\n",
      "Archivo MIDI guardado en: output1.mid\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    data_dir = '../dataset/music_artist/mozart'\n",
    "    print(\"Cargando datos...\")\n",
    "    pitches, cont, step_max, duration_max = load_all_data(data_dir)\n",
    "\n",
    "    (train_p, train_c), (val_p, val_c) = temporal_split_before_window(pitches, cont, split_ratio=SPLIT)\n",
    "\n",
    "    pitch_seqs_tr, cont_seqs_tr, pitch_tg_tr, cont_tg_tr = create_sequences(train_p, train_c, SEQ_LEN)\n",
    "    pitch_seqs_val, cont_seqs_val, pitch_tg_val, cont_tg_val = create_sequences(val_p, val_c, SEQ_LEN)\n",
    "\n",
    "    train_data = (pitch_seqs_tr, cont_seqs_tr, pitch_tg_tr, cont_tg_tr)\n",
    "    val_data   = (pitch_seqs_val, cont_seqs_val, pitch_tg_val, cont_tg_val)\n",
    "\n",
    "    model = MusicLSTMMultiOutput()\n",
    "    print(\"Entrenando modelo...\")\n",
    "    train(model, train_data, val_data, epochs=30, device=device)\n",
    "\n",
    "    print(\"Evaluando validación (todas las cabezas)...\")\n",
    "    metrics = evaluate_all(model, pitch_seqs_val, cont_seqs_val, pitch_tg_val, cont_tg_val,\n",
    "                           step_max, duration_max, device=device)\n",
    "    print(metrics)\n",
    "\n",
    "    print(\"Generando secuencia...\")\n",
    "    seed_pitch = pitch_seqs_tr[0].to(device)\n",
    "    seed_cont  = cont_seqs_tr[0].to(device)\n",
    "    gp, gc = generate_sequence_multi(model, seed_pitch, seed_cont, length=200,\n",
    "                                     temperature=TEMP, noise_std=NOISE_STD,\n",
    "                                     step_max=step_max, duration_max=duration_max,\n",
    "                                     device=device)\n",
    "    save_midi(gp, gc, \"output.mid\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
