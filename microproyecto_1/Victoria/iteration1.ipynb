{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac25240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEQ_LEN       = 50\n",
    "SPLIT         = 0.8\n",
    "LOSS_W_CONT   = 0.5\n",
    "TEMP          = 1.0\n",
    "NOISE_STD     = 0.05\n",
    "CAP_STEP      = 2.0\n",
    "CAP_DURATION  = 2.0\n",
    "SHOW_PPL      = True\n",
    "USE_SCHEDULER = True\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pretty_midi\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def extract_features(midi_file):\n",
    "    pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "    inst = pm.instruments[0]\n",
    "    notes = inst.notes\n",
    "\n",
    "    pitches, steps, durations, velocities = [], [], [], []\n",
    "    prev_time = 0.0\n",
    "\n",
    "    for i, note in enumerate(notes):\n",
    "        pitches.append(note.pitch)\n",
    "        start = note.start\n",
    "        dur = note.end - start\n",
    "        vel = note.velocity\n",
    "        step = start - prev_time if i > 0 else 0.0\n",
    "        steps.append(step); durations.append(dur); velocities.append(vel)\n",
    "        prev_time = start\n",
    "\n",
    "    steps = torch.tensor(steps, dtype=torch.float32)\n",
    "    durations = torch.tensor(durations, dtype=torch.float32)\n",
    "    velocities = torch.tensor(velocities, dtype=torch.float32)\n",
    "    pitches = torch.tensor(pitches, dtype=torch.long)\n",
    "\n",
    "    step_max = steps.max().item() + 0.00001\n",
    "    duration_max = durations.max().item() + 0.00001\n",
    "\n",
    "    steps = steps / step_max\n",
    "    durations = durations / duration_max\n",
    "    velocities = velocities / 127.0\n",
    "\n",
    "\n",
    "    cont_features = torch.stack([steps, durations, velocities], dim=1)\n",
    "    return pitches, cont_features, step_max, duration_max\n",
    "\n",
    "\n",
    "def load_all_data(dataset_dir):\n",
    "    pitches_all, cont_all = [], []\n",
    "    step_max_global, duration_max_global = 0.0, 0.0\n",
    "\n",
    "    for filename in sorted(os.listdir(dataset_dir)):\n",
    "        if filename.lower().endswith(('.mid', '.midi')):\n",
    "            p, c, step_max, duration_max = extract_features(os.path.join(dataset_dir, filename))\n",
    "            pitches_all.append(p); cont_all.append(c)\n",
    "            step_max_global = max(step_max_global, step_max)\n",
    "            duration_max_global = max(duration_max_global, duration_max)\n",
    "\n",
    "    pitches_all = torch.cat(pitches_all)\n",
    "    cont_all = torch.cat(cont_all)\n",
    "    return pitches_all, cont_all, step_max_global, duration_max_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83246db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(pitches, cont_features, seq_length):\n",
    "    pitch_seqs, cont_seqs, pitch_targets, cont_targets = [], [], [], []\n",
    "    for i in range(len(pitches) - seq_length):\n",
    "        pitch_seqs.append(pitches[i:i + seq_length])\n",
    "        cont_seqs.append(cont_features[i:i + seq_length])\n",
    "        pitch_targets.append(pitches[i + seq_length])\n",
    "        cont_targets.append(cont_features[i + seq_length])\n",
    "\n",
    "    return (torch.stack(pitch_seqs),\n",
    "            torch.stack(cont_seqs),\n",
    "            torch.tensor(pitch_targets),\n",
    "            torch.stack(cont_targets))\n",
    "\n",
    "\n",
    "def temporal_split_before_window(pitches, cont, split_ratio=0.8):\n",
    "    n_total = len(pitches)\n",
    "    cut = int(n_total * split_ratio)\n",
    "    return (pitches[:cut], cont[:cut]), (pitches[cut:], cont[cut:])\n",
    "\n",
    "\n",
    "class MusicLSTMMultiOutput(nn.Module):\n",
    "    def __init__(self, n_pitches=128, embed_size=32, hidden_size=128, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(n_pitches, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size + 3, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.hidden_fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.pitch_fc = nn.Linear(hidden_size, n_pitches)\n",
    "        self.cont_fc = nn.Linear(hidden_size, 3)\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "        pitch_emb = self.embed(pitch_seq)\n",
    "        x = torch.cat([pitch_emb, cont_seq], dim=2)\n",
    "        out, _ = self.lstm(x)\n",
    "        h = F.relu(self.hidden_fc(out[:, -1, :]))\n",
    "        return self.pitch_fc(h), self.cont_fc(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2eed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, epochs=20, batch_size=64, lr=0.001, device='cpu'):\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3, verbose=True) if USE_SCHEDULER else None\n",
    "\n",
    "    loss_pitch = nn.CrossEntropyLoss()\n",
    "    loss_cont  = nn.MSELoss()\n",
    "\n",
    "    train_pitch_seq, train_cont_seq, train_pitch_tgt, train_cont_tgt = train_data\n",
    "    val_pitch_seq,   val_cont_seq,   val_pitch_tgt,   val_cont_tgt   = val_data\n",
    "\n",
    "    val_pitch_seq = val_pitch_seq.to(device); val_cont_seq = val_cont_seq.to(device)\n",
    "    val_pitch_tgt = val_pitch_tgt.to(device); val_cont_tgt = val_cont_tgt.to(device)\n",
    "\n",
    "    n_train = len(train_pitch_seq)\n",
    "    steps_per_epoch = max(1, (n_train + batch_size - 1) // batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(n_train)\n",
    "        sum_loss = 0.0\n",
    "        sum_pitch_ce = 0.0\n",
    "        sum_acc = 0.0\n",
    "\n",
    "        for i in range(0, n_train, batch_size):\n",
    "            idx  = perm[i:i + batch_size]\n",
    "            pseq = train_pitch_seq[idx].to(device)\n",
    "            cseq = train_cont_seq[idx].to(device)\n",
    "            ptgt = train_pitch_tgt[idx].to(device)\n",
    "            ctgt = train_cont_tgt[idx].to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits, cont_out = model(pseq, cseq)\n",
    "            l_pitch = loss_pitch(logits, ptgt)\n",
    "            l_cont  = loss_cont(cont_out, ctgt)\n",
    "            loss = l_pitch + LOSS_W_CONT * l_cont\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            sum_loss    += loss.item()\n",
    "            sum_pitch_ce += l_pitch.item()\n",
    "            sum_acc     += (logits.argmax(dim=1) == ptgt).float().mean().item()\n",
    "\n",
    "        avg_train_loss = sum_loss / steps_per_epoch\n",
    "        avg_acc        = sum_acc  / steps_per_epoch\n",
    "        train_ppl      = math.exp(sum_pitch_ce / steps_per_epoch)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits, val_cont_out = model(val_pitch_seq, val_cont_seq)\n",
    "            val_ce   = loss_pitch(val_logits, val_pitch_tgt).item()\n",
    "            val_mse  = loss_cont(val_cont_out, val_cont_tgt).item()\n",
    "            val_loss = val_ce + LOSS_W_CONT * val_mse\n",
    "            val_acc  = (val_logits.argmax(dim=1) == val_pitch_tgt).float().mean().item()\n",
    "            val_ppl  = math.exp(val_ce)\n",
    "\n",
    "        msg = (f\"Ep {epoch + 1}/{epochs} | loss {avg_train_loss:.4f} | acc {avg_acc:.3f} | \"\n",
    "               f\"vloss {val_loss:.4f} | vacc {val_acc:.3f}\")\n",
    "        if SHOW_PPL:\n",
    "            msg += f\" | ppl {train_ppl:.2f} | vppl {val_ppl:.2f}\"\n",
    "        print(msg)\n",
    "\n",
    "        if sched is not None:\n",
    "            sched.step(val_loss)\n",
    "\n",
    "\n",
    "def sample_pitch(logits, temperature=1.0):\n",
    "    logits = logits / max(temperature, 0.00000001)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    return int(torch.multinomial(probs, 1).item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence_multi(model, seed_pitch, seed_cont, length=200, temperature=TEMP,\n",
    "                            noise_std=NOISE_STD, step_max=1.0, duration_max=1.0, device='cpu'):\n",
    "    model.eval()\n",
    "    out_p = []\n",
    "    out_c = []\n",
    "    pitch_seq = seed_pitch.clone().to(device)\n",
    "    cont_seq = seed_cont.clone().to(device)\n",
    "\n",
    "    for _ in range(length):\n",
    "        with torch.no_grad():\n",
    "            plogits, cout = model(pitch_seq.unsqueeze(0), cont_seq.unsqueeze(0))\n",
    "\n",
    "        pidx = sample_pitch(plogits.squeeze(0).cpu(), temperature)\n",
    "\n",
    "        cvals = cout.squeeze(0).cpu()\n",
    "        if noise_std > 0:\n",
    "            cvals = cvals + torch.randn(3) * noise_std\n",
    "        cvals = cvals.clamp(min=0.0)\n",
    "        cvals[0] = cvals[0] * step_max\n",
    "        cvals[1] = cvals[1] * duration_max\n",
    "        cvals[2] = cvals[2].clamp(max=1.0)\n",
    "\n",
    "        out_p.append(pidx)\n",
    "        out_c.append(cvals)\n",
    "\n",
    "        pitch_seq = torch.cat([pitch_seq[1:], torch.tensor([pidx], device=device)])\n",
    "        cont_seq = torch.cat([\n",
    "            cont_seq[1:],\n",
    "            (cvals / torch.tensor([step_max, duration_max, 1.0])).unsqueeze(0).to(device)\n",
    "        ])\n",
    "\n",
    "    return torch.tensor(out_p), torch.stack(out_c)\n",
    "\n",
    "def save_midi(pitches, cont_features, output_file):\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    inst = pretty_midi.Instrument(program=0)\n",
    "    t = 0.0\n",
    "\n",
    "    for i in range(len(pitches)):\n",
    "        pitch = int(pitches[i].item())\n",
    "        step = float(cont_features[i][0].item())\n",
    "        duration = float(cont_features[i][1].item())\n",
    "        velocity = int(cont_features[i][2].item() * 127)\n",
    "\n",
    "        if step > CAP_STEP:\n",
    "            step = CAP_STEP\n",
    "        if duration > CAP_DURATION:\n",
    "            duration = CAP_DURATION\n",
    "\n",
    "        t = t + step\n",
    "        start_time = t\n",
    "        end_time = start_time + max(duration, 0.05)\n",
    "        inst.notes.append(pretty_midi.Note(velocity=velocity, pitch=pitch, start=start_time, end=end_time))\n",
    "\n",
    "    pm.instruments.append(inst)\n",
    "    pm.write(output_file)\n",
    "    print(\"Archivo MIDI guardado en:\", output_file)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_all(model, pitch_seqs, cont_seqs, pitch_tg, cont_tg,\n",
    "                 step_max, duration_max, device='cpu', batch_size=1024):\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "    ce_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    pitch_seqs = pitch_seqs.to(device)\n",
    "    cont_seqs  = cont_seqs.to(device)\n",
    "    pitch_tg   = pitch_tg.to(device)\n",
    "    cont_tg    = cont_tg.to(device)\n",
    "\n",
    "    n = pitch_tg.size(0)\n",
    "    ce_sum = 0.0\n",
    "    acc_sum = 0.0\n",
    "    acc5_sum = 0.0\n",
    "    mse_n = torch.zeros(3)\n",
    "    mae_n = torch.zeros(3)\n",
    "    mse_r = torch.zeros(3)\n",
    "    mae_r = torch.zeros(3)\n",
    "\n",
    "    for i in range(0, n, batch_size):\n",
    "        pseq = pitch_seqs[i:i+batch_size]\n",
    "        cseq = cont_seqs[i:i+batch_size]\n",
    "        ptgt = pitch_tg[i:i+batch_size]\n",
    "        ctgt = cont_tg[i:i+batch_size]\n",
    "\n",
    "        logits, cpred = model(pseq, cseq)\n",
    "        ce_sum += ce_fn(logits, ptgt).item()\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        acc_sum += (pred == ptgt).float().sum().item()\n",
    "\n",
    "        top5 = logits.topk(5, dim=1).indices\n",
    "        acc5_sum += (top5 == ptgt.unsqueeze(1)).any(dim=1).float().sum().item()\n",
    "\n",
    "        diff_n = cpred - ctgt\n",
    "        mse_n += (diff_n ** 2).sum(dim=0).detach().cpu()\n",
    "        mae_n += diff_n.abs().sum(dim=0).detach().cpu()\n",
    "\n",
    "        den = torch.stack([\n",
    "            cpred[:, 0] * step_max,\n",
    "            cpred[:, 1] * duration_max,\n",
    "            cpred[:, 2].clamp(0, 1) * 127.0\n",
    "        ], dim=1)\n",
    "        den_t = torch.stack([\n",
    "            ctgt[:, 0] * step_max,\n",
    "            ctgt[:, 1] * duration_max,\n",
    "            ctgt[:, 2].clamp(0, 1) * 127.0\n",
    "        ], dim=1)\n",
    "\n",
    "        diff_r = den - den_t\n",
    "        mse_r += (diff_r ** 2).sum(dim=0).detach().cpu()\n",
    "        mae_r += diff_r.abs().sum(dim=0).detach().cpu()\n",
    "\n",
    "    ce = ce_sum / n\n",
    "    ppl = math.exp(ce)\n",
    "    acc = acc_sum / n\n",
    "    acc5 = acc5_sum / n\n",
    "\n",
    "    rmse_norm = (mse_n / n).sqrt().tolist()\n",
    "    mae_norm = (mae_n / n).tolist()\n",
    "    rmse_real = (mse_r / n).sqrt().tolist()\n",
    "    mae_real = (mae_r / n).tolist()\n",
    "\n",
    "    return {\n",
    "        \"pitch\": {\"CE\": ce, \"PPL\": ppl, \"acc\": acc, \"top5\": acc5},\n",
    "        \"cont_norm\": {\"RMSE\": rmse_norm, \"MAE\": mae_norm},\n",
    "        \"cont_real\": {\"RMSE_sec_vel\": rmse_real, \"MAE_sec_vel\": mae_real}\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
