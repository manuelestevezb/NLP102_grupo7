{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac25240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEQ_LEN       = 50\n",
    "SPLIT         = 0.8\n",
    "LOSS_W_CONT   = 0.5\n",
    "TEMP          = 1.0\n",
    "NOISE_STD     = 0.05\n",
    "CAP_STEP      = 2.0\n",
    "CAP_DURATION  = 2.0\n",
    "SHOW_PPL      = True\n",
    "USE_SCHEDULER = True\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pretty_midi\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def extract_features(midi_file):\n",
    "    pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "    inst = pm.instruments[0]\n",
    "    notes = inst.notes\n",
    "\n",
    "    pitches, steps, durations, velocities = [], [], [], []\n",
    "    prev_time = 0.0\n",
    "\n",
    "    for i, note in enumerate(notes):\n",
    "        pitches.append(note.pitch)\n",
    "        start = note.start\n",
    "        dur = note.end - start\n",
    "        vel = note.velocity\n",
    "        step = start - prev_time if i > 0 else 0.0\n",
    "        steps.append(step); durations.append(dur); velocities.append(vel)\n",
    "        prev_time = start\n",
    "\n",
    "    steps = torch.tensor(steps, dtype=torch.float32)\n",
    "    durations = torch.tensor(durations, dtype=torch.float32)\n",
    "    velocities = torch.tensor(velocities, dtype=torch.float32)\n",
    "    pitches = torch.tensor(pitches, dtype=torch.long)\n",
    "\n",
    "    step_max = steps.max().item() + 0.00001\n",
    "    duration_max = durations.max().item() + 0.00001\n",
    "\n",
    "    steps = steps / step_max\n",
    "    durations = durations / duration_max\n",
    "    velocities = velocities / 127.0\n",
    "\n",
    "\n",
    "    cont_features = torch.stack([steps, durations, velocities], dim=1)\n",
    "    return pitches, cont_features, step_max, duration_max\n",
    "\n",
    "\n",
    "def load_all_data(dataset_dir):\n",
    "    pitches_all, cont_all = [], []\n",
    "    step_max_global, duration_max_global = 0.0, 0.0\n",
    "\n",
    "    for filename in sorted(os.listdir(dataset_dir)):\n",
    "        if filename.lower().endswith(('.mid', '.midi')):\n",
    "            p, c, step_max, duration_max = extract_features(os.path.join(dataset_dir, filename))\n",
    "            pitches_all.append(p); cont_all.append(c)\n",
    "            step_max_global = max(step_max_global, step_max)\n",
    "            duration_max_global = max(duration_max_global, duration_max)\n",
    "\n",
    "    pitches_all = torch.cat(pitches_all)\n",
    "    cont_all = torch.cat(cont_all)\n",
    "    return pitches_all, cont_all, step_max_global, duration_max_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83246db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(pitches, cont_features, seq_length):\n",
    "    pitch_seqs, cont_seqs, pitch_targets, cont_targets = [], [], [], []\n",
    "    for i in range(len(pitches) - seq_length):\n",
    "        pitch_seqs.append(pitches[i:i + seq_length])\n",
    "        cont_seqs.append(cont_features[i:i + seq_length])\n",
    "        pitch_targets.append(pitches[i + seq_length])\n",
    "        cont_targets.append(cont_features[i + seq_length])\n",
    "\n",
    "    return (torch.stack(pitch_seqs),\n",
    "            torch.stack(cont_seqs),\n",
    "            torch.tensor(pitch_targets),\n",
    "            torch.stack(cont_targets))\n",
    "\n",
    "\n",
    "def temporal_split_before_window(pitches, cont, split_ratio=0.8):\n",
    "    n_total = len(pitches)\n",
    "    cut = int(n_total * split_ratio)\n",
    "    return (pitches[:cut], cont[:cut]), (pitches[cut:], cont[cut:])\n",
    "\n",
    "\n",
    "class MusicLSTMMultiOutput(nn.Module):\n",
    "    def __init__(self, n_pitches=128, embed_size=32, hidden_size=128, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(n_pitches, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size + 3, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.hidden_fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.pitch_fc = nn.Linear(hidden_size, n_pitches)\n",
    "        self.cont_fc = nn.Linear(hidden_size, 3)\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "        pitch_emb = self.embed(pitch_seq)\n",
    "        x = torch.cat([pitch_emb, cont_seq], dim=2)\n",
    "        out, _ = self.lstm(x)\n",
    "        h = F.relu(self.hidden_fc(out[:, -1, :]))\n",
    "        return self.pitch_fc(h), self.cont_fc(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2eed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, epochs=20, batch_size=64, lr=0.001, device='cpu'):\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3, verbose=True) if USE_SCHEDULER else None\n",
    "\n",
    "    loss_pitch = nn.CrossEntropyLoss()\n",
    "    loss_cont  = nn.MSELoss()\n",
    "\n",
    "    train_pitch_seq, train_cont_seq, train_pitch_tgt, train_cont_tgt = train_data\n",
    "    val_pitch_seq,   val_cont_seq,   val_pitch_tgt,   val_cont_tgt   = val_data\n",
    "\n",
    "    val_pitch_seq = val_pitch_seq.to(device); val_cont_seq = val_cont_seq.to(device)\n",
    "    val_pitch_tgt = val_pitch_tgt.to(device); val_cont_tgt = val_cont_tgt.to(device)\n",
    "\n",
    "    n_train = len(train_pitch_seq)\n",
    "    steps_per_epoch = max(1, (n_train + batch_size - 1) // batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(n_train)\n",
    "        sum_loss = 0.0\n",
    "        sum_pitch_ce = 0.0\n",
    "        sum_acc = 0.0\n",
    "\n",
    "        for i in range(0, n_train, batch_size):\n",
    "            idx  = perm[i:i + batch_size]\n",
    "            pseq = train_pitch_seq[idx].to(device)\n",
    "            cseq = train_cont_seq[idx].to(device)\n",
    "            ptgt = train_pitch_tgt[idx].to(device)\n",
    "            ctgt = train_cont_tgt[idx].to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits, cont_out = model(pseq, cseq)\n",
    "            l_pitch = loss_pitch(logits, ptgt)\n",
    "            l_cont  = loss_cont(cont_out, ctgt)\n",
    "            loss = l_pitch + LOSS_W_CONT * l_cont\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            sum_loss    += loss.item()\n",
    "            sum_pitch_ce += l_pitch.item()\n",
    "            sum_acc     += (logits.argmax(dim=1) == ptgt).float().mean().item()\n",
    "\n",
    "        avg_train_loss = sum_loss / steps_per_epoch\n",
    "        avg_acc        = sum_acc  / steps_per_epoch\n",
    "        train_ppl      = math.exp(sum_pitch_ce / steps_per_epoch)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits, val_cont_out = model(val_pitch_seq, val_cont_seq)\n",
    "            val_ce   = loss_pitch(val_logits, val_pitch_tgt).item()\n",
    "            val_mse  = loss_cont(val_cont_out, val_cont_tgt).item()\n",
    "            val_loss = val_ce + LOSS_W_CONT * val_mse\n",
    "            val_acc  = (val_logits.argmax(dim=1) == val_pitch_tgt).float().mean().item()\n",
    "            val_ppl  = math.exp(val_ce)\n",
    "\n",
    "        msg = (f\"Ep {epoch + 1}/{epochs} | loss {avg_train_loss:.4f} | acc {avg_acc:.3f} | \"\n",
    "               f\"vloss {val_loss:.4f} | vacc {val_acc:.3f}\")\n",
    "        if SHOW_PPL:\n",
    "            msg += f\" | ppl {train_ppl:.2f} | vppl {val_ppl:.2f}\"\n",
    "        print(msg)\n",
    "\n",
    "        if sched is not None:\n",
    "            sched.step(val_loss)\n",
    "\n",
    "\n",
    "def sample_pitch(logits, temperature=1.0):\n",
    "    logits = logits / max(temperature, 0.00000001)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    return int(torch.multinomial(probs, 1).item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
